{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from lavis.models import load_model_and_preprocess\n",
    "import os\n",
    "from torch.cuda.amp import autocast\n",
    "from downstream_model import PartModel, ACModel, GradeModel, load_and_transform_image\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "model, vis_processors, _ = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=True, device=device)\n",
    "\n",
    "Encoder = model.visual_encoder\n",
    "\n",
    "PartModel = PartModel()\n",
    "checkpoint_file = \"output/GIRepoter/Clspart_freeze_vitg_ep20-1.pth\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location='cpu')\n",
    "res = PartModel.load_state_dict(checkpoint, strict=False)\n",
    "PartModel = PartModel.to(device)\n",
    "\n",
    "ACModel = ACModel()\n",
    "checkpoint_file = \"output/GIRepoter/ours_bs64_lr3e-4_0213-002-8.pth\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location='cpu')\n",
    "res = ACModel.load_state_dict(checkpoint, strict=False)\n",
    "ACModel = ACModel.to(device)\n",
    "\n",
    "GradeModel = GradeModel()\n",
    "checkpoint_file = \"output/GIRepoter/Grad_freeze_vitg_ep30-1.pth\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location='cpu')\n",
    "res = GradeModel.load_state_dict(checkpoint, strict=False)\n",
    "GradeModel = GradeModel.to(device)\n",
    "\n",
    "Encoder.eval()\n",
    "PartModel.eval()\n",
    "ACModel.eval()\n",
    "GradeModel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomical Region Classification & Abnormal State Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path = \"sample_data/case_1\"\n",
    "case_list = [os.path.join(case_path, file) for file in os.listdir(case_path) if file.endswith('.jpg') or file.endswith('.png')]\n",
    "batchsize = 32\n",
    "\n",
    "all_results = []\n",
    "part_names = [\"Esophagus\", \"Cardia\", \"Gastric Fundus\", \"Gastric Body\", \"Gastric Angle\", \"Gastric Antrum and Pylorus\", \"Duodenum\"]\n",
    "part_names_chinese = [\"食道\", \"贲门\", \"胃底\", \"胃体\", \"胃角\", \"胃窦和幽门\", \"十二指肠\"]\n",
    "\n",
    "# Anatomical Region Classification & Abnormal State Recognition\n",
    "for i in range(0, len(case_list), batchsize):\n",
    "    batch_files = case_list[i:i+batchsize]\n",
    "\n",
    "    batch_images = torch.stack([\n",
    "        load_and_transform_image(file).to(device) for file in batch_files\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            feats = Encoder(batch_images)\n",
    "\n",
    "            parts_outputs = PartModel(feats)\n",
    "            parts_probs = torch.softmax(parts_outputs, dim=1)\n",
    "            _, parts_predicted = torch.max(parts_probs.data, 1)\n",
    "\n",
    "            part_confidences = parts_probs[range(len(parts_probs)), parts_predicted]\n",
    "\n",
    "            acs_outputs = ACModel(feats)\n",
    "            ac_probs = torch.softmax(acs_outputs, dim=1)\n",
    "            anomaly_scores = ac_probs[:, 1]\n",
    "\n",
    "    for file, part, ac_score, conf in zip(\n",
    "        batch_files,\n",
    "        parts_predicted.cpu().numpy(),\n",
    "        anomaly_scores.cpu().numpy(),\n",
    "        part_confidences.cpu().numpy()\n",
    "    ):\n",
    "        all_results.append({\n",
    "            \"filename\": os.path.basename(file),\n",
    "            \"filepath\": file,\n",
    "            \"part_id\": int(part),\n",
    "            \"part_name\": part_names[part],\n",
    "            \"anomaly_score\": float(ac_score),\n",
    "            \"part_confidence\": float(conf)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "grouped = df.groupby(\"part_name\", sort=False)\n",
    "\n",
    "images_description = {part_name: [] for part_name in part_names}\n",
    "images_conclusion = {part_name: [] for part_name in part_names}\n",
    "\n",
    "for part_name, group in grouped:\n",
    "    sorted_group = group.sort_values(by=\"anomaly_score\", ascending=False)\n",
    "    for idx, (_, row) in enumerate(sorted_group.iterrows()):\n",
    "        if len(images_description[part_name]) < 10:\n",
    "            images_description[part_name].append(row['filepath'])\n",
    "        if (part_name == \"Gastric Antrum and Pylorus\" and idx < 2) or \\\n",
    "           (part_name != \"Gastric Antrum and Pylorus\" and idx < 1):\n",
    "            images_conclusion[part_name].append(row['filepath'])\n",
    "\n",
    "print(\"Images for Region Description Generation:\")\n",
    "for part_name, images in images_description.items():\n",
    "    print(f\"{part_name}: {len(images)} images - {', '.join(images)}\")\n",
    "\n",
    "print(\"\\nImages for Diagnosis Conclusion Generation:\")\n",
    "for part_name, images in images_conclusion.items():\n",
    "    print(f\"{part_name}: {len(images)} images - {', '.join(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region Description Generation & Diagnosis Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region Description Generation\n",
    "region_descriptions = []\n",
    "for region, images in images_description.items():\n",
    "    images = [[vis_processors[\"eval\"](Image.open(image).convert(\"RGB\")).to(device) for image in images]]\n",
    "    response = model.generate({\"image\": images, \"prompt\": 'Please describe this set of gastroscopic images from the same gastric region.'})\n",
    "    region_descriptions.append(response[0])\n",
    "    print(f\"Region: {region}\")\n",
    "    print(f\"Description: {response[0]}\")\n",
    "    print('-' * 20)\n",
    "\n",
    "\n",
    "# Diagnosis Text Generation\n",
    "images = [[vis_processors[\"eval\"](Image.open(image).convert(\"RGB\")).to(device) for sublist in images_conclusion.values() for image in sublist]]\n",
    "response = model.generate({\"image\": images, \"prompt\": 'Please draw a diagnostic conclusion from this set of gastroscopy images.'})\n",
    "conclusion = response[0]\n",
    "print(f\"Conclusion: {response[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper GI Cancer Screening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = {0: \"high-risk\", 1: \"low-risk\"}\n",
    "grade_chinese = {0: \"高风险\", 1: \"低风险\"}\n",
    "\n",
    "batch_images = torch.stack([\n",
    "    load_and_transform_image(image).to(device) for sublist in images_conclusion.values() for image in sublist\n",
    "])\n",
    "\n",
    "# Upper GI Cancer Screening \n",
    "with torch.no_grad():\n",
    "    with autocast():\n",
    "        feats = Encoder(batch_images)\n",
    "        grade_logits = GradeModel(feats)\n",
    "        grade_probs = torch.softmax(grade_logits, dim=0)\n",
    "        grade_pred = torch.argmax(grade_probs).item()\n",
    "        print(f\"Result of Upper GI Cancer Screening: {grade[grade_pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_report import create_report_english, create_report_chinese\n",
    "create_report_chinese(region_descriptions, conclusion, images_conclusion, part_names, part_names_chinese, grade_chinese, grade_pred)\n",
    "create_report_english(region_descriptions, conclusion, images_conclusion, part_names, part_names_chinese, grade, grade_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
